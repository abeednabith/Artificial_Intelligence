{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Given observations, find hidden state sequence by viterbi algorithm\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "states = [\"B1\", \"B2\", \"B3\"]\n",
    "n_states = len(states)   # =3\n",
    "\n",
    "observations = [\"red\", \"red\", \"yellow\", \"green\"]\n",
    "n_observations = len(observations)\n",
    "\n",
    "start_probability = np.array([0.4, 0.35, 0.25])\n",
    "\n",
    "transition_probability = np.array([\n",
    "  [0.3, 0.2, 0.5],\n",
    "  [0.1, 0.3, 0.6],\n",
    "  [0.7, 0.25, 0.05]\n",
    "])\n",
    "\n",
    "emission_probability = np.array([\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.2, 0.4, 0.4],\n",
    "  [0.15, 0.25, 0.6]\n",
    "])\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=n_states) \n",
    "# MultinomialHMM: observation distribution in Multinomial\n",
    "model.startprob_=start_probability\n",
    "model.transmat_=transition_probability\n",
    "model.emissionprob_=emission_probability\n",
    "\n",
    "seen = np.array([[0,1,0,1]]).T        # 0: red;     1: white   => r w r\n",
    "logprob, box = model.decode(seen, algorithm=\"viterbi\")\n",
    "seen = [0,1,0]\n",
    "print(\"The ball picked:\", \", \".join(map(lambda x: observations[x], seen)))\n",
    "print(\"The hidden box:\", \", \".join(map(lambda x: states[x], box)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Or find state sequence by \"predict\" function \n",
    "\"\"\"\n",
    "seen = np.array([[0,1,0,1]]).T  \n",
    "box2 = model.predict(seen)      # same as \"viterbi\"\n",
    "seen = [0,1,0]\n",
    "print(\"The ball picked:\", \", \".join(map(lambda x: observations[x], seen)))\n",
    "print(\"The hidden box:\", \", \".join(map(lambda x: states[x], box2)))\n",
    "\n",
    "\"\"\"\n",
    "    Find probability of observation sequence\n",
    "\"\"\"\n",
    "seen = np.array([[0,1,0,1]]).T                   # P(rwr) =?\n",
    "print(model.score(seen))\n",
    "# ln(P(red*white*red)) = -2.038545309915233   # P(rwr) = exp(-2.038545309915233)\n",
    "\n",
    "\"\"\"\n",
    "    Given observation sequences, find transition/emission matrix \n",
    "    and initial probabilities in Baum-Welch algorithm\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "states = [\"box 1\", \"box 2\", \"box3\"]\n",
    "n_states = len(states)\n",
    "\n",
    "observations = [\"red\", \"white\"]\n",
    "n_observations = len(observations)\n",
    "model2 = hmm.MultinomialHMM(n_components=n_states, n_iter=20, tol=0.01)\n",
    "X2 = np.array([[0,1,0,1],[0,0,0,1],[1,0,1,1]])\n",
    "model2.fit(X2)\n",
    "print(model2.startprob_)\n",
    "print(model2.transmat_)\n",
    "print(model2.emissionprob_)\n",
    "print(model2.score(X2))\n",
    "model2.fit(X2)\n",
    "print(model2.startprob_)\n",
    "print(model2.transmat_)\n",
    "print(model2.emissionprob_)\n",
    "print(model2.score(X2))\n",
    "model2.fit(X2)\n",
    "# print(model2.startprob_)\n",
    "# print(model2.transmat_)\n",
    "# print(model2.emissionprob_)\n",
    "# print(model2.score(X2))\n",
    "\n",
    "\"\"\"\n",
    "    Select optimal one of above running results as final solution because Baum-Welch algorithm take EM approximate method\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "    Taking GaussianHMM model\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "startprob = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "# The transition matrix, note that there are no transitions possible\n",
    "# between component 1 and 3\n",
    "transmat = np.array([[0.7, 0.2, 0.0, 0.1],\n",
    "                     [0.3, 0.5, 0.2, 0.0],\n",
    "                     [0.0, 0.3, 0.5, 0.2],\n",
    "                     [0.2, 0.0, 0.2, 0.6]])\n",
    "# The means of each component\n",
    "means = np.array([[0.0,  0.0],\n",
    "                  [0.0, 11.0],\n",
    "                  [9.0, 10.0],\n",
    "                  [11.0, -1.0]])\n",
    "# The covariance of each component\n",
    "covars = .5 * np.tile(np.identity(2), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model3 = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model3.startprob_ = startprob\n",
    "model3.transmat_ = transmat\n",
    "model3.means_ = means\n",
    "model3.covars_ = covars\n",
    "\n",
    "seen = np.array([[1.1,2.0],[-1,2.0],[3,7]])\n",
    "logprob, state = model3.decode(seen, algorithm=\"viterbi\")\n",
    "print(state)\n",
    "print(model3.score(seen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a2adf9a08ea23ac2e3332469154c91ad6304789584be7b5db1dc0a647ad5b67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
